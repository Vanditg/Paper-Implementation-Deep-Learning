{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-10 GAN RGB",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCKWVEsmK51r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython import display\n",
        "from torch import nn, optim\n",
        "from torch.autograd.variable import Variable\n",
        "from torchvision import transforms, datasets\n",
        "from tensorboardX import SummaryWriter\n",
        "from matplotlib import pyplot as plt\n",
        "import torchvision.datasets as dset\n",
        "import os\n",
        "import numpy as np\n",
        "import errno\n",
        "import torchvision.utils as vutils\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOhvD0D3M8WP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Logger:\n",
        "\n",
        "    def __init__(self, model_name, data_name):\n",
        "        self.model_name = model_name\n",
        "        self.data_name = data_name\n",
        "\n",
        "        self.comment = '{}_{}'.format(model_name, data_name)\n",
        "        self.data_subdir = '{}/{}'.format(model_name, data_name)\n",
        "\n",
        "        # TensorBoard\n",
        "        self.writer = SummaryWriter(comment=self.comment)\n",
        "\n",
        "    def log(self, d_error, g_error, epoch, n_batch, num_batches):\n",
        "\n",
        "        # var_class = torch.autograd.variable.Variable\n",
        "        if isinstance(d_error, torch.autograd.Variable):\n",
        "            d_error = d_error.data.cpu().numpy()\n",
        "        if isinstance(g_error, torch.autograd.Variable):\n",
        "            g_error = g_error.data.cpu().numpy()\n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/D_error'.format(self.comment), d_error, step)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/G_error'.format(self.comment), g_error, step)\n",
        "\n",
        "    def log_images(self, images, num_images, epoch, n_batch, num_batches, format='NCHW', normalize=True):\n",
        "        '''\n",
        "        input images are expected in format (NCHW)\n",
        "        '''\n",
        "        if type(images) == np.ndarray:\n",
        "            images = torch.from_numpy(images)\n",
        "        \n",
        "        if format=='NHWC':\n",
        "            images = images.transpose(1,3)\n",
        "        \n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        img_name = '{}/images{}'.format(self.comment, '')\n",
        "\n",
        "        # Make horizontal grid from image tensor\n",
        "        horizontal_grid = vutils.make_grid(\n",
        "            images, normalize=normalize, scale_each=True)\n",
        "        # Make vertical grid from image tensor\n",
        "        nrows = int(np.sqrt(num_images))\n",
        "        grid = vutils.make_grid(\n",
        "            images, nrow=nrows, normalize=True, scale_each=True)\n",
        "\n",
        "        # Add horizontal images to tensorboard\n",
        "        self.writer.add_image(img_name, horizontal_grid, step)\n",
        "\n",
        "        # Save plots\n",
        "        self.save_torch_images(horizontal_grid, grid, epoch, n_batch)\n",
        "\n",
        "    def save_torch_images(self, horizontal_grid, grid, epoch, n_batch, plot_horizontal=True):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "\n",
        "        # Plot and save horizontal\n",
        "        fig = plt.figure(figsize=(16, 16))\n",
        "        plt.imshow(np.moveaxis(horizontal_grid.numpy(), 0, -1))\n",
        "        plt.axis('off')\n",
        "        if plot_horizontal:\n",
        "            display.display(plt.gcf())\n",
        "        self._save_images(fig, epoch, n_batch, 'hori')\n",
        "        plt.close()\n",
        "\n",
        "        # Save squared\n",
        "        fig = plt.figure()\n",
        "        plt.imshow(np.moveaxis(grid.numpy(), 0, -1))\n",
        "        plt.axis('off')\n",
        "        self._save_images(fig, epoch, n_batch)\n",
        "        plt.close()\n",
        "\n",
        "    def _save_images(self, fig, epoch, n_batch, comment=''):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        fig.savefig('{}/{}_epoch_{}_batch_{}.png'.format(out_dir,\n",
        "                                                         comment, epoch, n_batch))\n",
        "\n",
        "    def display_status(self, epoch, num_epochs, n_batch, num_batches, d_error, g_error, d_pred_real, d_pred_fake):\n",
        "        \n",
        "        # var_class = torch.autograd.variable.Variable\n",
        "        if isinstance(d_error, torch.autograd.Variable):\n",
        "            d_error = d_error.data.cpu().numpy()\n",
        "        if isinstance(g_error, torch.autograd.Variable):\n",
        "            g_error = g_error.data.cpu().numpy()\n",
        "        if isinstance(d_pred_real, torch.autograd.Variable):\n",
        "            d_pred_real = d_pred_real.data\n",
        "        if isinstance(d_pred_fake, torch.autograd.Variable):\n",
        "            d_pred_fake = d_pred_fake.data\n",
        "        \n",
        "        \n",
        "        print('Epoch: [{}/{}], Batch Num: [{}/{}]'.format(\n",
        "            epoch,num_epochs, n_batch, num_batches)\n",
        "             )\n",
        "        print('Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(d_error, g_error))\n",
        "        print('D(x): {:.4f}, D(G(z)): {:.4f}'.format(d_pred_real.mean(), d_pred_fake.mean()))\n",
        "\n",
        "    def save_models(self, generator, discriminator, epoch):\n",
        "        out_dir = './data/models/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        torch.save(generator.state_dict(),\n",
        "                   '{}/G_epoch_{}'.format(out_dir, epoch))\n",
        "        torch.save(discriminator.state_dict(),\n",
        "                   '{}/D_epoch_{}'.format(out_dir, epoch))\n",
        "\n",
        "    def close(self):\n",
        "        self.writer.close()\n",
        "\n",
        "    # Private Functionality\n",
        "\n",
        "    @staticmethod\n",
        "    def _step(epoch, n_batch, num_batches):\n",
        "        return epoch * num_batches + n_batch\n",
        "\n",
        "    @staticmethod\n",
        "    def _make_dir(directory):\n",
        "        try:\n",
        "            os.makedirs(directory)\n",
        "        except OSError as e:\n",
        "            if e.errno != errno.EEXIST:\n",
        "                raise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dyTiWJyK8Rp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "26ba0158-b701-4094-c385-b5fb30e3fd99"
      },
      "source": [
        "dataset = dset.CIFAR10(root=\"./data\", download=True,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ]))\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)\n",
        "num_batches = len(data_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vbVl_gbNCPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiscriminatorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A three hidden-layer discriminative neural network\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorNet, self).__init__()\n",
        "        n_features = 3072\n",
        "        n_out = 1\n",
        "        \n",
        "        self.hidden0 = nn.Sequential( \n",
        "            nn.Linear(n_features, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.hidden2 = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.out = nn.Sequential(\n",
        "            torch.nn.Linear(256, n_out),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "    \n",
        "def images_to_vectors(images):\n",
        "    return images.view(images.size(0), 3072)\n",
        "\n",
        "def vectors_to_images(vectors):\n",
        "    return vectors.view(vectors.size(0), 3, 32, 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibFEYCA0K_El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GeneratorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A three hidden-layer generative neural network\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(GeneratorNet, self).__init__()\n",
        "        n_features = 100\n",
        "        n_out = 3072\n",
        "        \n",
        "        self.hidden0 = nn.Sequential(\n",
        "            nn.Linear(n_features, 256),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(            \n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.hidden2 = nn.Sequential(\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        \n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(1024, n_out),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "    \n",
        "# Noise\n",
        "def noise(size):\n",
        "  n = Variable(torch.randn(size, 100))\n",
        "  if torch.cuda.is_available(): return n.cuda() \n",
        "  return n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzRre5NGLbEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = DiscriminatorNet()\n",
        "generator = GeneratorNet()\n",
        "if torch.cuda.is_available():\n",
        "    discriminator.cuda()\n",
        "    generator.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZtji0_2Lj1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizers\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
        "\n",
        "# Loss function\n",
        "loss = nn.BCELoss()\n",
        "\n",
        "# Number of steps to apply to the discriminator\n",
        "d_steps = 1  # In Goodfellow et. al 2014 this variable is assigned to 1\n",
        "# Number of epochs\n",
        "num_epochs = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPBKHYF7Ofdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def real_data_target(size):\n",
        "    '''\n",
        "    Tensor containing ones, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.ones(size, 1))\n",
        "    if torch.cuda.is_available(): return data.cuda()\n",
        "    return data\n",
        "\n",
        "def fake_data_target(size):\n",
        "    '''\n",
        "    Tensor containing zeros, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.zeros(size, 1))\n",
        "    if torch.cuda.is_available(): return data.cuda()\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpselPN2L1x-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_discriminator(optimizer, real_data, fake_data):\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # 1.1 Train on Real Data\n",
        "    prediction_real = discriminator(real_data)\n",
        "    # Calculate error and backpropagate\n",
        "    error_real = loss(prediction_real, real_data_target(real_data.size(0)))\n",
        "    error_real.backward()\n",
        "\n",
        "    # 1.2 Train on Fake Data\n",
        "    prediction_fake = discriminator(fake_data)\n",
        "    # Calculate error and backpropagate\n",
        "    error_fake = loss(prediction_fake, fake_data_target(real_data.size(0)))\n",
        "    error_fake.backward()\n",
        "    \n",
        "    # 1.3 Update weights with gradients\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Return error\n",
        "    return error_real + error_fake, prediction_real, prediction_fake\n",
        "\n",
        "def train_generator(optimizer, fake_data):\n",
        "    # 2. Train Generator\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "    # Sample noise and generate fake data\n",
        "    prediction = discriminator(fake_data)\n",
        "    # Calculate error and backpropagate\n",
        "    error = loss(prediction, real_data_target(prediction.size(0)))\n",
        "    error.backward()\n",
        "    # Update weights with gradients\n",
        "    optimizer.step()\n",
        "    # Return error\n",
        "    return error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDDAwKhpL4tY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "num_test_samples = 16\n",
        "test_noise = noise(num_test_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMvJVdOTL7TX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "44ef512a-a3d3-41c5-de26-0ed87a7eca1f"
      },
      "source": [
        "logger = Logger(model_name='VGAN', data_name='CIFAR10')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for n_batch, (real_batch,_) in enumerate(data_loader):\n",
        "\n",
        "        # 1. Train Discriminator\n",
        "        real_data = Variable(images_to_vectors(real_batch))\n",
        "        if torch.cuda.is_available(): real_data = real_data.cuda()\n",
        "        # Generate fake data\n",
        "        fake_data = generator(noise(real_data.size(0))).detach()\n",
        "        # Train D\n",
        "        d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer,\n",
        "                                                                real_data, fake_data)\n",
        "\n",
        "        # 2. Train Generator\n",
        "        # Generate fake data\n",
        "        fake_data = generator(noise(real_batch.size(0)))\n",
        "        # Train G\n",
        "        g_error = train_generator(g_optimizer, fake_data)\n",
        "        # Log error\n",
        "        logger.log(d_error, g_error, epoch, n_batch, num_batches)\n",
        "\n",
        "        # Display Progress\n",
        "        if (n_batch) % 100 == 0:\n",
        "            display.clear_output(True)\n",
        "            # Display Images\n",
        "            test_images = vectors_to_images(generator(test_noise)).data.cpu()\n",
        "            logger.log_images(test_images, num_test_samples, epoch, n_batch, num_batches);\n",
        "            # Display status Logs\n",
        "            logger.display_status(\n",
        "                epoch, num_epochs, n_batch, num_batches,\n",
        "                d_error, g_error, d_pred_real, d_pred_fake\n",
        "            )\n",
        "        # Model Checkpoints\n",
        "        logger.save_models(generator, discriminator, epoch)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a35093f130f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'VGAN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'CIFAR10'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreal_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Logger' is not defined"
          ]
        }
      ]
    }
  ]
}